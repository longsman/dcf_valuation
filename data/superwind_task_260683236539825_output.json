{"metadata":{"job_id":413747026668475,"run_id":260683236539825,"creator_user_name":"datsando@outlook.com","number_in_job":260683236539825,"original_attempt_run_id":260683236539825,"state":{"life_cycle_state":"TERMINATED","result_state":"FAILED","state_message":"Workload failed, see run output for details","user_cancelled_or_timedout":false},"task":{"notebook_task":{"notebook_path":"notebooks/exec-superwind","base_parameters":{"yaml_file":"../pipelines/polygon/bronze.polygon.snapshot_all_tickers.yaml"},"source":"GIT"}},"cluster_spec":{"job_cluster_key":"Job_cluster","libraries":[{"pypi":{"package":"feedparser==6.0.11"}},{"pypi":{"package":"pydantic==2.8.2"}},{"pypi":{"package":"ratelimit==2.2.1"}},{"pypi":{"package":"pyyaml==6.0.2"}},{"pypi":{"package":"keyring==25.3.0"}}]},"cluster_instance":{"cluster_id":"1111-140008-0ux6st1s","spark_context_id":"8046187868758907920"},"start_time":1762869604324,"setup_duration":184000,"execution_duration":58000,"cleanup_duration":0,"end_time":1762869847077,"trigger":"ONE_TIME","run_name":"bronze-polygon-snapshot_all_tickers","run_page_url":"https://dbc-51f1a5f2-687a.cloud.databricks.com/?o=683875129393773#job/413747026668475/run/260683236539825","run_type":"JOB_RUN","parent_run_id":1108041584533723,"task_key":"bronze-polygon-snapshot_all_tickers","attempt_number":0,"format":"SINGLE_TASK","git_source":{"git_url":"https://github.com/datsando/superwind","git_provider":"gitHub","git_commit":"6d882e122075cac1929bcf0ea36869777a2d6ef3","git_snapshot":{"used_commit":"6d882e122075cac1929bcf0ea36869777a2d6ef3"}},"status":{"state":"TERMINATED","termination_details":{"code":"RUN_EXECUTION_ERROR","type":"CLIENT_ERROR","message":"Workload failed, see run output for details"}},"job_run_id":1108041584533723},"error":"[DELTA_MERGE_UNRESOLVED_EXPRESSION] Cannot resolve tab.ticker in search condition given columns tab._id, tab.snapshot_date, tab.access_ts, tab.headers, tab.content, tab._footprint, inc._id, inc.ticker, inc.todayschangeperc, inc.todayschange, inc.updated, inc.day, inc.lastquote, inc.lasttrade, inc.min, inc.prevday, inc.snapshot_date, inc._footprint. SQLSTATE: 42601","error_trace":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-6439760513583148>, line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m pdef \u001B[38;5;241m=\u001B[39m parser\u001B[38;5;241m.\u001B[39mload(dbutils\u001B[38;5;241m.\u001B[39mnotebook\u001B[38;5;241m.\u001B[39mentry_point\u001B[38;5;241m.\u001B[39mgetCurrentBindings()[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124myaml_file\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(parser\u001B[38;5;241m.\u001B[39mdumps(pdef))\n\u001B[0;32m----> 9\u001B[0m pdef\u001B[38;5;241m.\u001B[39mrun()\n\nFile \u001B[0;32m/Workspace/Repos/.internal/0d32d6e3dc_commits/6d882e122075cac1929bcf0ea36869777a2d6ef3/superwind/definition/__init__.py:115\u001B[0m, in \u001B[0;36mPipelineDefinition.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    113\u001B[0m p \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_pipeline()\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ExecutionMode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmode) \u001B[38;5;241m==\u001B[39m ExecutionMode\u001B[38;5;241m.\u001B[39mBATCH:\n\u001B[0;32m--> 115\u001B[0m     \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    117\u001B[0m     p\u001B[38;5;241m.\u001B[39mrun_stream(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mcheckpoint_path, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mstreaming_trigger_mode, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mstreaming_defer_operators)\n\nFile \u001B[0;32m/Workspace/Repos/.internal/0d32d6e3dc_commits/6d882e122075cac1929bcf0ea36869777a2d6ef3/superwind/definition/__init__.py:54\u001B[0m, in \u001B[0;36mPipeline.run_batch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_batch\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 54\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconsumer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconsume\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_df\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mExecutionMode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBATCH\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/Workspace/Repos/.internal/0d32d6e3dc_commits/6d882e122075cac1929bcf0ea36869777a2d6ef3/superwind/consumers/catalog.py:160\u001B[0m, in \u001B[0;36mMergeTable.consume\u001B[0;34m(self, df, _)\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete_when_not_matched_by_source:\n\u001B[1;32m    158\u001B[0m     merge\u001B[38;5;241m.\u001B[39mwhenNotMatchedBySourceDelete()\n\u001B[0;32m--> 160\u001B[0m \u001B[43mmerge\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/delta/tables.py:1216\u001B[0m, in \u001B[0;36mDeltaMergeBuilder.execute\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1209\u001B[0m \u001B[38;5;129m@since\u001B[39m(\u001B[38;5;241m0.4\u001B[39m)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m   1210\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexecute\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1211\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1212\u001B[0m \u001B[38;5;124;03m    Execute the merge operation based on the built matched and not matched actions.\u001B[39;00m\n\u001B[1;32m   1213\u001B[0m \n\u001B[1;32m   1214\u001B[0m \u001B[38;5;124;03m    See :py:class:`~delta.tables.DeltaMergeBuilder` for complete usage details.\u001B[39;00m\n\u001B[1;32m   1215\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1216\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1356\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [DELTA_MERGE_UNRESOLVED_EXPRESSION] Cannot resolve tab.ticker in search condition given columns tab._id, tab.snapshot_date, tab.access_ts, tab.headers, tab.content, tab._footprint, inc._id, inc.ticker, inc.todayschangeperc, inc.todayschange, inc.updated, inc.day, inc.lastquote, inc.lasttrade, inc.min, inc.prevday, inc.snapshot_date, inc._footprint.","notebook_output":{}}