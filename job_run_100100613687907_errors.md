# Job Run Error Report

**Job ID:** 259919585799043  
**Original Run ID:** 100100613687907  
**Run Name:** [dev la_long_n] pipeline_equities  
**Report Date:** 2026-01-14  

---

## Executive Summary

The original job run `100100613687907` failed with **11 task failures** caused by **missing Unity Catalog schemas**. After multiple rounds of fixes, the latest run `304903880711412` shows significant improvement:

| Metric | Original Run | Latest Run |
|--------|--------------|------------|
| **Successful Tasks** | 8 | 20 |
| **Failed Tasks** | 11 | 2 |
| **Skipped Tasks** | 8 | 5 |
| **Total Tasks** | 27 | 27 |

---

## Fixes Applied

### 1. Created Missing Unity Catalog Schemas (RESOLVED)

**Issue:** 6 schemas in the `gold` catalog did not exist.

**Fix Applied:**
```sql
CREATE SCHEMA IF NOT EXISTS gold.damodaran;
CREATE SCHEMA IF NOT EXISTS gold.valuation;
CREATE SCHEMA IF NOT EXISTS gold.dim;
CREATE SCHEMA IF NOT EXISTS gold.financials;
CREATE SCHEMA IF NOT EXISTS gold.edgar;
CREATE SCHEMA IF NOT EXISTS gold.market;
```

**Result:** All 11 original `SCHEMA_NOT_FOUND` errors are now resolved.

---

### 2. Fixed ExecSQL Parameter Name (RESOLVED)

**Issue:** Pipeline YAML files used `sql:` instead of `sql_query:` for the `ExecSQL` operator.

**Files Fixed:**
- `gold/financials.statement_lines/pipeline.yaml`
- `gold/valuation.dcf_inputs/pipeline.yaml`

**Error:**
```
ValidationError: 1 validation error for ExecSQL
sql
  Extra inputs are not permitted [type=extra_forbidden]
```

**Result:** Pydantic validation errors resolved.

---

### 3. Fixed VOID Column Type Issues (RESOLVED)

**Issue:** SQL queries with `null as column_name` created VOID type columns that Delta Lake couldn't merge.

**Files Fixed:**
- `gold/dim.cik_ticker/pipeline.yaml`: Changed `null as cik` to `cast(null as string) as cik`
- `gold/dim.company/pipeline.yaml`: Changed `null as sic` to `cast(null as int) as sic`

**Error:**
```
[DELTA_MERGE_ADD_VOID_COLUMN] Cannot add column `cik` with type VOID
```

**Result:** VOID column errors resolved; tables now created successfully.

---

### 4. Fixed Delta CDF Version Issues (PARTIALLY RESOLVED)

**Issue:** Streaming pipelines using `startingVersion: 0` failed because old Delta table versions were vacuumed.

**Changes Made:**
- Updated `checkpoint_path` to use new paths (`_v3` suffix) to bypass corrupted checkpoints
- Changed `startingVersion` default from `0` to `latest`

**Error:**
```
VersionNotFoundException: Cannot time travel Delta table to version 0. Available versions: [2313, 2585]
```

**Result:** Version errors resolved, but `startingVersion: latest` means no historical data is processed on first run.

---

## Current Status (Run 304903880711412)

### Successful Tasks (20)

| Layer | Task | Status |
|-------|------|--------|
| Bronze | `bronze-edgar-form10_filings_rss` | SUCCESS |
| Bronze | `bronze-massive-snapshot_all_tickers` | SUCCESS |
| Bronze | `bronze-fred-series_observations` | SUCCESS |
| Bronze | `bronze-edgar-company_facts` | SUCCESS |
| Silver | `silver-edgar-form10_filings_rss` | SUCCESS |
| Silver | `silver-massive-snapshot_all_tickers` | SUCCESS |
| Silver | `silver-fred-market_yield_10yr` | SUCCESS |
| Silver | `silver-edgar-company_facts` | SUCCESS |
| Gold | `gold-damodaran-ratings_spreads` | SUCCESS |
| Gold | `gold-damodaran-synthetic_rating_bands` | SUCCESS |
| Gold | `gold-damodaran-implied_erp` | SUCCESS |
| Gold | `gold-damodaran-industry_betas` | SUCCESS |
| Gold | `gold-valuation-assumption_sets` | SUCCESS |
| Gold | `gold-dim-sic_to_damodaran_industry` | SUCCESS |
| Gold | `gold-dim-cik_ticker` | SUCCESS |
| Gold | `gold-dim-company` | SUCCESS |
| Gold | `gold-financials-tag_map` | SUCCESS |
| Gold | `gold-edgar-filing_events` | SUCCESS |
| Gold | `gold-financials-statement_lines` | SUCCESS (no output) |
| Gold | `gold-market-prices_daily` | SUCCESS (no output) |

### Failed Tasks (2)

| Task | Error | Root Cause |
|------|-------|------------|
| `gold-financials-flow_quarterly` | `TABLE_OR_VIEW_NOT_FOUND: gold.financials.statement_lines` | Upstream table empty |
| `gold-financials-balance_quarterly` | `TABLE_OR_VIEW_NOT_FOUND: gold.financials.statement_lines` | Upstream table empty |

### Skipped Tasks (5)

| Task | Reason |
|------|--------|
| `gold-financials-flow_ttm` | Upstream `gold-financials-flow_quarterly` failed |
| `gold-financials-working_capital` | Upstream `gold-financials-balance_quarterly` failed |
| `gold-valuation-dcf_inputs` | Multiple upstream failures |
| `gold-valuation-dcf_cashflows` | Upstream `gold-valuation-dcf_inputs` skipped |
| `gold-valuation-dcf_results` | Upstream `gold-valuation-dcf_cashflows` skipped |

---

## Remaining Issue

### No Historical Data Backfill

**Problem:** The `gold-financials-statement_lines` pipeline ran successfully but produced no output because:
1. The streaming checkpoint was reset (new path `_v3`)
2. `startingVersion: latest` was set to avoid version errors
3. No new CDF data arrived during the job run

**Impact:** The `gold.financials.statement_lines` table doesn't exist, causing downstream tasks to fail.

**Required Action:** Run a one-time backfill for the streaming pipelines using a valid historical version:

```bash
# Option 1: Run with environment variable override
databricks jobs run-now 259919585799043 \
  --python-named-params '{"CDF_STARTING_VERSION": "2313"}'

# Option 2: Update pipeline YAML to use batch mode for initial load
# Then switch back to streaming for incremental updates
```

---

## Code Changes Summary

Files modified in `pipeline_equities/src/pipeline_equities/assets/`:

| File | Change |
|------|--------|
| `gold/financials.statement_lines/pipeline.yaml` | `sql` → `sql_query`, checkpoint `_v3`, `startingVersion: latest` |
| `gold/valuation.dcf_inputs/pipeline.yaml` | `sql` → `sql_query` |
| `gold/dim.cik_ticker/pipeline.yaml` | `null as cik` → `cast(null as string) as cik` |
| `gold/dim.company/pipeline.yaml` | `null as sic` → `cast(null as int) as sic` |
| `gold/market.prices_daily/pipeline.yaml` | checkpoint `_v3`, `startingVersion: latest` |

---

## Links

- [Original Run (100100613687907)](https://dbc-51f1a5f2-687a.cloud.databricks.com/?o=683875129393773#job/259919585799043/run/100100613687907)
- [Latest Run (304903880711412)](https://dbc-51f1a5f2-687a.cloud.databricks.com/?o=683875129393773#job/259919585799043/run/304903880711412)
